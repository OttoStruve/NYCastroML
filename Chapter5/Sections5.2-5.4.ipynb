{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 5, Sections 5.2-5.4"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5.2. Bayesian Priors"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.2.1. Priors Assigned by Formal Rules"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several different kinds of priors that you might encounter.\n",
      "\n",
      "- **informative prior**: A prior that incorporates actual data.\n",
      "- **uninformative prior**: A prior that does not use actual data, but could still be meaningful, *e.g.* 'the parameter must be non-negative'.\n",
      "  - **improper prior**: A prior that cannot be formulated as a formal PDF.\n",
      "  - **flat prior**: A prior that is constant, $p(\\theta|I) \\propto C$.  These can be improper.\n",
      "  - **principle of indifference**: Assign equal probabilities to all, mutually-exclusive possibilities.\n",
      "  - **principle of consistency**: Priors assigned to 'location' parameters should be translation-invariant.  Priors assigned to 'scale' paramters should not depend on the choice of units."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.2.2. The Principle of Maximum Entropy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maximum Entropy is used for cases where we have slightly more information about a parameter.  Maybe not enough for a fully-informative prior, but more than would warrant an uninformative prior.  This definition comes from Information Theory and is sometimes called \"Shannon's Entropy\".  For a discrete PDF:\n",
      "\n",
      "$$S=-\\sum_{i=1}^N p_i \\ln p_i$$\n",
      "\n",
      "For a continuous PDF:\n",
      "\n",
      "$$S = - \\int_{-\\infty}^\\infty p(x) \\ln \\frac{p(x)}{m(x)} \\mathrm{d}x$$\n",
      "\n",
      "What does the \"measure\", $m(x)$ *really* do?  Recall that a continuous PDF has units of $x^{-1}$.  So when we stuff $p(x)$ inside a logarithm, we have to cancel out those units.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.2.3. Conjugate Priors"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.2.4. Empirical and Hierarchical Bayes Methods"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5.3. Bayesian Parameter Uncertainty Quantification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.3.1. Posterior Intervals"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.3.2. Marginalization of Parameters"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5.4. Bayesian Model Selection"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.4.1. Bayesian Hypothesis Testing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.4.2. Occam's Razor"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.4.3. Information Criteria"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}